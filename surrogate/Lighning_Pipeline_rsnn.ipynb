{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6f6a2f7-0936-4b99-8fa3-4a691a70192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snntorch as snn\n",
    "from snntorch import spikeplot as splt\n",
    "from snntorch import spikegen\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import pytorch_lightning as L\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "import wandb\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ca2435a-0ea8-4808-a117-c2cc88b7a203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['X_train', 'Y_train', 'X_valid', 'Y_valid', 'X_test', 'Y_test'])\n",
      "torch.Size([28797, 106, 1])\n",
      "torch.Size([28797, 100])\n"
     ]
    }
   ],
   "source": [
    "# Our data in in the shape: trainings samples(28k) * number of time steps (100 + 6) * time dimension(1)\n",
    "# The time steps is voltage over time\n",
    "data = torch.load(f'./data/dataset.ds')\n",
    "\n",
    "print(data.keys())\n",
    "print(data['X_train'].shape)\n",
    "print(data['Y_train'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8931f32-fee5-4807-9777-b640599f1963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract tensors\n",
    "X_train, Y_train = data['X_train'], data['Y_train']\n",
    "X_valid, Y_valid = data['X_valid'], data['Y_valid']\n",
    "X_test, Y_test = data['X_test'], data['Y_test']\n",
    "\n",
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "valid_dataset = TensorDataset(X_valid, Y_valid)\n",
    "test_dataset  = TensorDataset(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1da032d-51df-4d26-ad4c-585894b3cb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikeSynth(L.LightningModule):\n",
    "    def __init__(self, num_hidden_layers, num_hidden, beta, optimizer_class, lr, batch_size, gamma):\n",
    "        super().__init__()\n",
    "        self.num_params = 6\n",
    "        self.num_inputs = 1\n",
    "        self.num_outputs = 100\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.lif_layers = nn.ModuleList()\n",
    "\n",
    "        input_size = self.num_inputs + self.num_params\n",
    "        for _ in range(self.hparams.num_hidden_layers):\n",
    "            self.lif_layers.append(\n",
    "                snn.LeakyParallel(\n",
    "                    input_size=input_size,\n",
    "                    hidden_size=self.hparams.num_hidden,\n",
    "                    beta=self.hparams.beta\n",
    "                )\n",
    "            )\n",
    "            # After first layer, input_size = hidden_size\n",
    "            input_size = self.hparams.num_hidden\n",
    "\n",
    "        self.output_layer = nn.Linear(self.hparams.num_hidden, self.num_inputs)\n",
    "\n",
    "    def forward(self, x, params=None):\n",
    "      # Ensure x is 3D: (batch, seq_len, 1)\n",
    "      if x.dim() == 2:\n",
    "          x = x.unsqueeze(-1)\n",
    "      elif x.dim() != 3:\n",
    "          raise ValueError(f\"x must be 2D or 3D, got {x.shape}\")\n",
    "\n",
    "      batch, seq_len, _ = x.shape  # channels is always 1\n",
    "\n",
    "      # Handle static parameters\n",
    "      if params is not None:\n",
    "        if params.dim() < 2:\n",
    "          raise ValueError(f\"params must have at least 2 dimensions (batch size x static parameters), got {params.shape}\")\n",
    "        if params.shape[1] < self.num_params:\n",
    "          raise ValueError(f\"params must have at least {self.num_params} parameters per batch, got {params.shape[1]}\")\n",
    "\n",
    "        # Expand params across the time dimension\n",
    "        params_expanded = params.unsqueeze(2)\n",
    "        x = torch.cat([x, params_expanded], dim=1)\n",
    "\n",
    "      else:\n",
    "        # Assume last 6 timesteps of x are static params if not provided\n",
    "        if seq_len <= self.num_params:\n",
    "            raise ValueError(f\"x sequence too short to contain static params, got seq_len={seq_len}\")\n",
    "        x_features = x  # dynamic + static already included\n",
    "\n",
    "      static_params = x[:, :self.num_params, 0]  # shape: (batch_size, 6)\n",
    "      time_series = x[:, self.num_params:, 0]    # shape: (batch_size, time_series_length)\n",
    "      time_steps = time_series.shape[1]\n",
    "\n",
    "      # Repeat static parameters for each time step\n",
    "      static_repeated = static_params.unsqueeze(1).repeat(1, time_steps, 1)  # shape: (batch_size, time_steps, 6)\n",
    "\n",
    "      # Add the current time step value as the last feature\n",
    "      time_series_features = time_series.unsqueeze(2)  # shape: (batch_size, time_steps, 1)\n",
    "\n",
    "      # Concatenate static + time series\n",
    "      x_transformed = torch.cat([static_repeated, time_series_features], dim=2)  # shape: (batch_size, time_steps, 7)\n",
    "      x_seq = x_transformed.permute(1, 0, 2)  # shape: (time_steps, batch_size, 7)\n",
    "\n",
    "      # Forward through all LIF layers\n",
    "      for lif in self.lif_layers:\n",
    "          x_seq = lif(x_seq)  # (L, batch, hidden_size)\n",
    "\n",
    "      # Take last timestep\n",
    "      last = x_seq[-1]  # (batch, hidden_size)\n",
    "      out = self.output_layer(last)  # (batch, num_outputs)\n",
    "\n",
    "      return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X_batch, y_batch = batch\n",
    "        outputs = self(X_batch)\n",
    "        loss = torch.nn.MSELoss()(outputs, y_batch.float())\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X_batch, y_batch = batch\n",
    "        outputs = self(X_batch)\n",
    "        loss = torch.nn.MSELoss()(outputs, y_batch.float())\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        opt = self.optimizers()\n",
    "        lr = opt.param_groups[0][\"lr\"]\n",
    "        self.log(\"lr\", lr, prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = self.hparams.optimizer_class(self.parameters(), lr=self.hparams.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
    "            optimizer, gamma=self.hparams.gamma\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": scheduler,\n",
    "            \"monitor\": \"val_loss\",\n",
    "        }\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=8,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            valid_dataset,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=4,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ffa0732-3896-4e38-ab60-0a88215d7508",
   "metadata": {},
   "outputs": [],
   "source": [
    " model = SpikeSynth(\n",
    "        optimizer_class=torch.optim.AdamW,\n",
    "        beta=0.9,\n",
    "        lr=0.01,\n",
    "        num_hidden=10,\n",
    "        batch_size=1024,\n",
    "        gamma=0.9,\n",
    "        num_hidden_layers=2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "715654cc-32d2-4114-9269-c0fd50f3f495",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type       | Params | Mode \n",
      "----------------------------------------------------\n",
      "0 | lif_layers   | ModuleList | 410    | train\n",
      "1 | output_layer | Linear     | 11     | train\n",
      "----------------------------------------------------\n",
      "221       Trainable params\n",
      "200       Non-trainable params\n",
      "421       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "6         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "292a1bd3ffba4147991d69d4ec075cd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nix/store/qsg98l1y41k4530xsn0ss82xrd03095c-python3-3.12.11-env/lib/python3.12/site-packages/torch/nn/modules/loss.py:616: UserWarning: Using a target size (torch.Size([576, 100])) that is different to the input size (torch.Size([576, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/nix/store/qsg98l1y41k4530xsn0ss82xrd03095c-python3-3.12.11-env/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (29) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cde9a3239b94d9f87d90424165b5725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                    | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nix/store/qsg98l1y41k4530xsn0ss82xrd03095c-python3-3.12.11-env/lib/python3.12/site-packages/torch/nn/modules/loss.py:616: UserWarning: Using a target size (torch.Size([125, 100])) that is different to the input size (torch.Size([125, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed486973bbfd4c1b9add298b6ce14182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                  | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19da688c9fa249d9ad79261aea2327fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                  | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a1cbe942fc44a9090d82adecf2af1f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                  | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a43d6373e4534244a5d5b69b01aaaaea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                  | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49bc060bed7348e5b722bd0471dd7c6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                  | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    #fast_dev_run=True,\n",
    "    max_epochs=5,\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7247728-7483-4e9b-8c2e-b34652f056d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2497]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1, 1)\n",
    "model(x, torch.tensor([[0.1, 0.2, 0.3, 0.4, 0.5, 0.6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0deb127-74a4-4940-b3fe-8a6c83fc8921",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
