method: random
metric:
  name: val_loss
  goal: minimize
parameters:
  lr:
    value: 0.005
  num_hidden:
    value: [2, 4, 8, 16, 32, 64]
  # Defines the Decay of the LIF Neurons
  beta:
    value: [0.3, 0.5, 0.8]
  surrogate_gradient:
      value: "atan"
  # Slope of the surrogate gradient function
  alpha:
      value: [2, 4, 8, 16]
  dropout:
      value: 0
  batch_size:
    value: 2048
  optimizer_class:
    value: "AdamW"
  num_hidden_layers:
      value: [1, 2, 4, 8, 16]
  temporal_skip:
      value: -1
  use_bntt:
      value: False
  bntt_time_steps:
      value: 100
  layer_skip:
      value: 0
  scheduler_class:
    value: "cosine" # ["cosine", "exponential", "step", "plateau"]
  scheduler_kwargs:
    value: ""
  epochs:
    value: 25
run_cap: 50
