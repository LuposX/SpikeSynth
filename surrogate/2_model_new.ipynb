{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a938a98c-2079-4008-82f5-945074eb595f",
   "metadata": {},
   "source": [
    "This Notebook is for training the surrogate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac07a5a4-f306-477e-8b3e-1a447c383dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd())\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import training\n",
    "import config\n",
    "import MyTransformer_lP as MyTransformer\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9a4b350-8e63-4961-9035-163f4378f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "models = ['gpt-nano', 'gpt-micro', 'gpt-mini', 'gopher-44m', 'gpt2']\n",
    "\n",
    "seed  = 0\n",
    "model_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1e9547-b102-4a24-940a-7c2bced7baed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The experiment setup is gpt-nano_lr_-2_seed_0.\n",
      "number of parameters: 0.09M\n",
      "The ID for this training is -8452096691130601980_1759759524.\n"
     ]
    }
   ],
   "source": [
    "for lr in tqdm(range(-2, -7, -1)):\n",
    "\n",
    "    exp_setup = f'{models[model_idx]}_lr_{lr}_seed_{seed}'\n",
    "    print(f'The experiment setup is {exp_setup}.')\n",
    "\n",
    "    if os.path.exists(f'./NNs/predictor_{exp_setup}'):\n",
    "        pass\n",
    "    else:\n",
    "        data = torch.load(f'./data/dataset.ds')\n",
    "\n",
    "\n",
    "        X_train = data['X_train'].to(device)\n",
    "        Y_train = data['Y_train'].to(device)\n",
    "        X_valid = data['X_valid'].to(device)\n",
    "        Y_valid = data['Y_valid'].to(device)\n",
    "        X_test  = data['X_test'].to(device)\n",
    "        Y_test  = data['Y_test'].to(device)\n",
    "\n",
    "        train_data = TensorDataset(X_train, Y_train)\n",
    "        valid_data = TensorDataset(X_valid, Y_valid)\n",
    "        test_data  = TensorDataset(X_test, Y_test)\n",
    "\n",
    "        train_loader = DataLoader(train_data, batch_size=128)\n",
    "        valid_loader = DataLoader(valid_data, batch_size=128)\n",
    "        test_loader  = DataLoader(test_data, batch_size=128)\n",
    "\n",
    "        config.SetSeed(seed)\n",
    "\n",
    "        model_config = MyTransformer.GPT.get_default_config()\n",
    "        model_config.model_type = models[model_idx]\n",
    "        model_config.block_size = X_train.shape[1]\n",
    "        model = MyTransformer.GPT(model_config).to(device)\n",
    "\n",
    "        lossfunction = torch.nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=10**lr)\n",
    "\n",
    "        model, train_loss, valid_loss = training.train_nn(model, train_loader, valid_loader, lossfunction, optimizer, UUID=exp_setup)\n",
    "        torch.save(model, f'./NNs/predictor_{exp_setup}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df13a2c0-6523-4fa0-9c17-2b4c0a88a5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
