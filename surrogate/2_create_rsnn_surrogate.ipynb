{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72e36e96-8d12-4e6d-8fd6-8038c6c6b33b",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6f6a2f7-0936-4b99-8fa3-4a691a70192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snntorch as snn\n",
    "from snntorch import spikeplot as splt\n",
    "from snntorch import spikegen\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import pytorch_lightning as L\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "import wandb\n",
    "\n",
    "import os\n",
    "\n",
    "from utils.RSNN import SpikeSynth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1599185-e6a8-4280-832f-888ff03d7d9f",
   "metadata": {},
   "source": [
    "## 2. Dataset Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ca2435a-0ea8-4808-a117-c2cc88b7a203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['X_train', 'Y_train', 'X_valid', 'Y_valid', 'X_test', 'Y_test'])\n",
      "torch.Size([28797, 106, 1])\n",
      "torch.Size([28797, 100])\n"
     ]
    }
   ],
   "source": [
    "# Our data in in the shape: trainings samples(28k) * number of time steps (100 + 6) * time dimension(1)\n",
    "# The time steps is voltage over time\n",
    "data = torch.load(f'./data/dataset.ds')\n",
    "\n",
    "print(data.keys())\n",
    "print(data['X_train'].shape)\n",
    "print(data['Y_train'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8931f32-fee5-4807-9777-b640599f1963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract tensors\n",
    "X_train, Y_train = data['X_train'], data['Y_train']\n",
    "X_valid, Y_valid = data['X_valid'], data['Y_valid']\n",
    "X_test, Y_test = data['X_test'], data['Y_test']\n",
    "\n",
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "valid_dataset = TensorDataset(X_valid, Y_valid)\n",
    "test_dataset  = TensorDataset(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff4764d-f7e0-49ab-9406-680256a91f49",
   "metadata": {},
   "source": [
    "## 3. Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ffa0732-3896-4e38-ab60-0a88215d7508",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs=10\n",
    "experiment_name=\"test\" # Changes wandb expeirment name\n",
    "project_name = \"Spike-Synth-Surrogate\" # Changes where wandb project\n",
    "logging_directory = \".temp\"\n",
    "checkpoint_path = \"models/SRNN\" # where the final checkpoint is saved\n",
    "\n",
    "model = SpikeSynth(\n",
    "        optimizer_class=torch.optim.AdamW,\n",
    "        beta=0.9,\n",
    "        lr=0.005,\n",
    "        num_hidden=256,\n",
    "        batch_size=2048,\n",
    "        gamma=0.9,\n",
    "        num_hidden_layers=4,\n",
    "        train_dataset=train_dataset,\n",
    "        valid_dataset=valid_dataset,\n",
    "        max_epochs=max_epochs,\n",
    "        surrogate_gradient=snn.surrogate.atan(),\n",
    "        temporal_skip=None,\n",
    "        layer_skip=2\n",
    "    )\n",
    "\n",
    "script_dir = os.getcwd() \n",
    "logging_directory = os.path.join(script_dir, logging_directory)\n",
    "logging_directory = os.path.abspath(logging_directory)\n",
    "os.makedirs(logging_directory, exist_ok=True)\n",
    "os.environ[\"WANDB_DIR\"] = logging_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de17b082-d87b-4df3-a109-eefb2583e7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlupos\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/monkeman/SpikeSynth/surrogate/.temp/wandb/run-20251026_205954-oo7lt06j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lupos/Spike-Synth-Surrogate/runs/oo7lt06j' target=\"_blank\">test</a></strong> to <a href='https://wandb.ai/lupos/Spike-Synth-Surrogate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lupos/Spike-Synth-Surrogate' target=\"_blank\">https://wandb.ai/lupos/Spike-Synth-Surrogate</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lupos/Spike-Synth-Surrogate/runs/oo7lt06j' target=\"_blank\">https://wandb.ai/lupos/Spike-Synth-Surrogate/runs/oo7lt06j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Artifact source-Spike-Synth-Surrogate-surrogate_2_create_rsnn_surrogate.ipynb>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a CometLogger instance\n",
    "wandb_logger = WandbLogger(\n",
    "                          log_model=True,\n",
    "                          project=project_name,\n",
    "                          name=experiment_name,\n",
    "                          save_dir=logging_directory\n",
    "                          )\n",
    "\n",
    "# log gradients and model topology\n",
    "wandb_logger.watch(model)\n",
    "wandb_logger.experiment.log_code(\".\", include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65791ae-5d9b-4e9f-a3fd-a088e83bfc05",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "715654cc-32d2-4114-9269-c0fd50f3f495",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/nix/store/mxb5f60mz822vg50ll0pz7063spw4bnr-python3-3.12.11-env/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:751: Checkpoint directory /home/monkeman/SpikeSynth/surrogate/models/SRNN exists and is not empty.\n",
      "\n",
      "  | Name              | Type          | Params | Mode \n",
      "------------------------------------------------------------\n",
      "0 | norm              | LayerNorm     | 14     | train\n",
      "1 | lif_layers        | ModuleList    | 462 K  | train\n",
      "2 | residual_alphas   | ParameterList | 4      | train\n",
      "3 | residual_projs    | ModuleList    | 2.0 K  | train\n",
      "4 | layer_skip_alphas | ParameterList | 2      | train\n",
      "5 | layer_skip_projs  | ModuleList    | 131 K  | train\n",
      "6 | output_layer      | Linear        | 257    | train\n",
      "------------------------------------------------------------\n",
      "334 K     Trainable params\n",
      "262 K     Non-trainable params\n",
      "596 K     Total params\n",
      "2.386     Total estimated model params size (MB)\n",
      "21        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efdd9d043f0a41ce9db9778a6c10d0fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nix/store/mxb5f60mz822vg50ll0pz7063spw4bnr-python3-3.12.11-env/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:1481: UserWarning: Dynamo does not know how to trace the builtin `<unknown module>.set.add.` This function is either a Python builtin (e.g. _warnings.warn) or a third-party C/C++ Python extension (perhaps created with pybind).\n",
      "If it is a Python builtin, please file an issue on GitHub so the PyTorch team can add support for it and see the next case for a workaround.\n",
      "If it is a third-party C/C++ Python extension, please either wrap it into a PyTorch-understood custom operator (see https://pytorch.org/tutorials/advanced/custom_ops_landing_page.html for more details) or, if it is traceable, use `torch.compiler.allow_in_graph`.\n",
      "  torch._dynamo.utils.warn_once(explanation + \"\\n\" + \"\\n\".join(hints))\n",
      "/nix/store/mxb5f60mz822vg50ll0pz7063spw4bnr-python3-3.12.11-env/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2547c2b1aeb04b8990273be75be5ad70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                    | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nix/store/mxb5f60mz822vg50ll0pz7063spw4bnr-python3-3.12.11-env/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3707: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=checkpoint_path,\n",
    "    filename=experiment_name + str(\"spike_model-{epoch:02d}-{val_loss:.2f}\"),\n",
    "    save_top_k=1,  # save only the best model\n",
    "    monitor=\"val_loss\",  # metric to monitor\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    logger=wandb_logger, \n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "model = torch.compile(model)\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model)\n",
    "\n",
    "wandb_logger.finalize(\"sucess\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9849c5cc-8504-4772-9cb3-2cb36520d3e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
