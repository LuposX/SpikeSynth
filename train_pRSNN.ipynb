{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ac9738a-5c03-46bd-8a19-32d74a5aedbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configuration import load_args\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "from utils import FormulateArgs, MakeFolder, SetSeed\n",
    "from utils.Loader import GetDataLoader\n",
    "from utils.logger import GetMessageLogger\n",
    "import utils.training as training\n",
    "\n",
    "import PrintedSpikingNN_lP_New as pSNN\n",
    "from surrogate.RSNN import SpikeSynth\n",
    "\n",
    "import pprint\n",
    "import os\n",
    "import time\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc5ba82e-29ab-4c0b-a8df-c6686d05ddc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all our arguments for training\n",
    "\n",
    "args = load_args(overrides={\n",
    "    \"DATASET\": 0,\n",
    "    \"SEED\": 0,\n",
    "    \"projectname\": \"pLR-SNN\",\n",
    "    \"DEVICE\": \"cpu\",\n",
    "    \"PROGRESSIVE\": True,\n",
    "    \"EPOCH\": 100,\n",
    "    \"TIMELIMITATION\": 0.1,\n",
    "    \"LR_MIN\": 5e-2,\n",
    "    \"LR\": 0.1,\n",
    "})\n",
    "\n",
    "args = FormulateArgs(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bd84a6a-d5d8-40cb-9427-778ded9a7894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'N_class': 2,\n",
      " 'N_feature': 6,\n",
      " 'N_test': 25,\n",
      " 'N_time': 100,\n",
      " 'N_train': 70,\n",
      " 'N_valid': 23,\n",
      " 'dataname': 'acuteinflammation'}\n"
     ]
    }
   ],
   "source": [
    "# Dataset Definition\n",
    "train_loader, datainfo = GetDataLoader(args, 'train')\n",
    "valid_loader, datainfo = GetDataLoader(args, 'valid')\n",
    "test_loader, datainfo = GetDataLoader(args, 'test')\n",
    "pprint.pprint(datainfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4be8ac1a-d899-42c8-8c30-ca0bb1d7e561",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for SpikeSynth:\n\tMissing key(s) in state_dict: \"norm.weight\", \"norm.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m psnn = \u001b[43mpSNN\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLightningPrintedSpikingNetwork\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtopology\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdatainfo\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mN_feature\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mdatainfo\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mN_class\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSpikeSynth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msurrogate/checkpoints-srnn/spike_model-epoch=92-val_loss=0.07.ckpt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SpikeSynth/PrintedSpikingNN_lP_New.py:18\u001b[39m, in \u001b[36mLightningPrintedSpikingNetwork.__init__\u001b[39m\u001b[34m(self, topology, args, model_class, ckpt_path, train_loader, valid_loader, test_loader, loss_fn)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mself\u001b[39m.save_hyperparameters(ignore=[\u001b[33m'\u001b[39m\u001b[33mmodel_class\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mckpt_path\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mloss_fn\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     17\u001b[39m \u001b[38;5;28mself\u001b[39m.args = args\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28mself\u001b[39m.network = \u001b[43mPrintedSpikingNeuralNetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopology\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# loss_fn expects (model, x, y) -> scalar (matches your LFLoss)\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mself\u001b[39m.loss_fn = loss_fn \u001b[38;5;28;01mif\u001b[39;00m loss_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m LFLoss(args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SpikeSynth/PrintedSpikingNN_lP_New.py:326\u001b[39m, in \u001b[36mPrintedSpikingNeuralNetwork.__init__\u001b[39m\u001b[34m(self, topology, args, model_class, ckpt_path)\u001b[39m\n\u001b[32m    324\u001b[39m \u001b[38;5;28mself\u001b[39m.model = torch.nn.Sequential()\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(topology)-\u001b[32m1\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28mself\u001b[39m.model.add_module(\u001b[38;5;28mstr\u001b[39m(i)+\u001b[33m'\u001b[39m\u001b[33m_pLayer\u001b[39m\u001b[33m'\u001b[39m, \u001b[43mpLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopology\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopology\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mINV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SpikeSynth/PrintedSpikingNN_lP_New.py:203\u001b[39m, in \u001b[36mpLayer.__init__\u001b[39m\u001b[34m(self, n_in, n_out, args, INV, model_class, ckpt_path)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28mself\u001b[39m.args = args\n\u001b[32m    202\u001b[39m \u001b[38;5;66;03m# define spike generators\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m \u001b[38;5;28mself\u001b[39m.SG = \u001b[43mSGLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[38;5;66;03m# define nonlinear circuits\u001b[39;00m\n\u001b[32m    205\u001b[39m \u001b[38;5;28mself\u001b[39m.INV = INV\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SpikeSynth/PrintedSpikingNN_lP_New.py:164\u001b[39m, in \u001b[36mSGLayer.__init__\u001b[39m\u001b[34m(self, N, args, model_class, ckpt_path)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m    162\u001b[39m \u001b[38;5;28mself\u001b[39m.args = args\n\u001b[32m    163\u001b[39m \u001b[38;5;28mself\u001b[39m.SG_Group = torch.nn.ModuleList(\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     [\u001b[43mpSpikeGenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N)])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SpikeSynth/PrintedSpikingNN_lP_New.py:113\u001b[39m, in \u001b[36mpSpikeGenerator.__init__\u001b[39m\u001b[34m(self, args, model_class, ckpt_path)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28mself\u001b[39m.args = args\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m# Load frozen spike generator\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m \u001b[38;5;28mself\u001b[39m.spike_generator = \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[38;5;28mself\u001b[39m.spike_generator.train(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.spike_generator.parameters():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nix/store/mxb5f60mz822vg50ll0pz7063spw4bnr-python3-3.12.11-env/lib/python3.12/site-packages/pytorch_lightning/utilities/model_helpers.py:125\u001b[39m, in \u001b[36m_restricted_classmethod_impl.__get__.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m instance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scripting:\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    122\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe classmethod `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.method.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` cannot be called on an instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    123\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m Please call it on the class type and make sure the return value is used.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    124\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nix/store/mxb5f60mz822vg50ll0pz7063spw4bnr-python3-3.12.11-env/lib/python3.12/site-packages/pytorch_lightning/core/module.py:1662\u001b[39m, in \u001b[36mLightningModule.load_from_checkpoint\u001b[39m\u001b[34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[39m\n\u001b[32m   1573\u001b[39m \u001b[38;5;129m@_restricted_classmethod\u001b[39m\n\u001b[32m   1574\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_from_checkpoint\u001b[39m(\n\u001b[32m   1575\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1580\u001b[39m     **kwargs: Any,\n\u001b[32m   1581\u001b[39m ) -> Self:\n\u001b[32m   1582\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\u001b[39;00m\n\u001b[32m   1583\u001b[39m \u001b[33;03m    passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[32m   1584\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1660\u001b[39m \n\u001b[32m   1661\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1662\u001b[39m     loaded = \u001b[43m_load_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1663\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1664\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1665\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1666\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1667\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1668\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1669\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1670\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Self, loaded)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nix/store/mxb5f60mz822vg50ll0pz7063spw4bnr-python3-3.12.11-env/lib/python3.12/site-packages/pytorch_lightning/core/saving.py:91\u001b[39m, in \u001b[36m_load_from_checkpoint\u001b[39m\u001b[34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _load_state(\u001b[38;5;28mcls\u001b[39m, checkpoint, **kwargs)\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, pl.LightningModule):\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     model = \u001b[43m_load_state\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m     state_dict = checkpoint[\u001b[33m\"\u001b[39m\u001b[33mstate_dict\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m state_dict:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nix/store/mxb5f60mz822vg50ll0pz7063spw4bnr-python3-3.12.11-env/lib/python3.12/site-packages/pytorch_lightning/core/saving.py:187\u001b[39m, in \u001b[36m_load_state\u001b[39m\u001b[34m(cls, checkpoint, strict, **cls_kwargs_new)\u001b[39m\n\u001b[32m    184\u001b[39m     obj.on_load_checkpoint(checkpoint)\n\u001b[32m    186\u001b[39m \u001b[38;5;66;03m# load the state_dict on the model automatically\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m keys = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstate_dict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m strict:\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m keys.missing_keys:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nix/store/mxb5f60mz822vg50ll0pz7063spw4bnr-python3-3.12.11-env/lib/python3.12/site-packages/torch/nn/modules/module.py:2624\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2616\u001b[39m         error_msgs.insert(\n\u001b[32m   2617\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2618\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2619\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2620\u001b[39m             ),\n\u001b[32m   2621\u001b[39m         )\n\u001b[32m   2623\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2624\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2625\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2626\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2627\u001b[39m         )\n\u001b[32m   2628\u001b[39m     )\n\u001b[32m   2629\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for SpikeSynth:\n\tMissing key(s) in state_dict: \"norm.weight\", \"norm.bias\". "
     ]
    }
   ],
   "source": [
    "psnn = pSNN.LightningPrintedSpikingNetwork(\n",
    "    topology=[datainfo['N_feature']] + args.hidden + [datainfo['N_class']], \n",
    "    args=args, \n",
    "    model_class=SpikeSynth, \n",
    "    ckpt_path=\"surrogate/checkpoints-srnn/spike_model-epoch=92-val_loss=0.07.ckpt\",\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    test_loader=test_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a0a554-2500-46c3-bb7a-f63291aaaf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CometLogger instance\n",
    "wandb_logger = WandbLogger(\n",
    "                          log_model=True,\n",
    "                          project=\"Spike-Synth-Full\",\n",
    "                          name=\"Surrogate_SRNN_ReduceLROnPlateau\",\n",
    "                          )\n",
    "\n",
    "# log gradients and model topology\n",
    "wandb_logger.watch(psnn)\n",
    "wandb_logger.experiment.log_code(\".\", include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373f6481-95d1-4925-a3ec-67d074536675",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints-pLR-SNN/\",\n",
    "    filename=\"pLRSNN-{epoch:02d}-{val_loss:.2f}\",\n",
    "    save_top_k=1,  # save only the best model\n",
    "    monitor=\"val_loss\",  # metric to monitor\n",
    "    mode=\"min\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef92fd4-008d-44c0-b6de-d9e470bc8d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    # fast_dev_run=True,\n",
    "    max_epochs=args.EPOCH,\n",
    "    logger=wandb_logger,  \n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(psnn)\n",
    "\n",
    "wandb_logger.experiment.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3cba16-c2df-4080-9020-0475d62282da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
